{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471a3335-4595-41b5-a377-fe17d4b926bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f031e7ba-0e29-461f-b551-b605205e9f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "parent_folder = 'nli_dataset'\n",
    "language_codes = [name for name in os.listdir(parent_folder)\n",
    "                if os.path.isdir(os.path.join(parent_folder, name))]\n",
    "language_codes.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cb4ecf2-056e-4dfa-b95e-a07cf6bc5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_code_to_name = {\n",
    "    'amh': 'Amharic',\n",
    "    'ara': 'Arabic',\n",
    "    'asm': 'Assamese',\n",
    "    'aym': 'Aymara',\n",
    "    'ben': 'Bengali',\n",
    "    'bul': 'Bulgarian',\n",
    "    'bzd': 'Bribri',\n",
    "    'cat': 'Catalan',\n",
    "    'cni': 'Asháninka',\n",
    "    'deu': 'German',\n",
    "    'ell': 'Greek',\n",
    "    'eng': 'English',\n",
    "    'ewe': 'Ewe',\n",
    "    'fra': 'French',\n",
    "    'grn': 'Guarani',\n",
    "    'guj': 'Gujarati',\n",
    "    'hau': 'Hausa',\n",
    "    'hch': 'Wixarika',\n",
    "    'hin': 'Hindi',\n",
    "    'ibo': 'Igbo',\n",
    "    'ind': 'Indonesian',\n",
    "    'jpn': 'Japanese',\n",
    "    'kan': 'Kannada',\n",
    "    'kin': 'Kinyarwanda',\n",
    "    'kor': 'Korean',\n",
    "    'lin': 'Lingala',\n",
    "    'lug': 'Luganda',\n",
    "    'mal': 'Malayalam',\n",
    "    'mar': 'Marathi',\n",
    "    'mya': 'Burmese',\n",
    "    'nah': 'Nahuatl',\n",
    "    'ori': 'Odia (Oriya)',\n",
    "    'orm': 'Oromo',\n",
    "    'oto': 'Otomi',\n",
    "    'pan': 'Punjabi',\n",
    "    'pat': 'Jamaican Patois',\n",
    "    'pol': 'Polish',\n",
    "    'por': 'Portuguese',\n",
    "    'quy': 'Quechua',\n",
    "    'ron': 'Romanian',\n",
    "    'rus': 'Russian',\n",
    "    'shp': 'Shipibo-Conibo',\n",
    "    'sna': 'chiShona',\n",
    "    'sot': 'Sesotho',\n",
    "    'spa': 'Spanish',\n",
    "    'swa': 'Swahili',\n",
    "    'tam': 'Tamil',\n",
    "    'tar': 'Rarámuri',\n",
    "    'tel': 'Telugu',\n",
    "    'tha': 'Thai',\n",
    "    'tur': 'Turkish',\n",
    "    'twi': 'Twi',\n",
    "    'urd': 'Urdu',\n",
    "    'vie': 'Vietnamese',\n",
    "    'wol': 'Wolof',\n",
    "    'xho': 'isiXhosa',\n",
    "    'yor': 'Yoruba',\n",
    "    'zho': 'Chinese',\n",
    "    'zul': 'isiZulu'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d15ed787-2335-4249-8793-ed117ba66ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Given the following premise and hypothesis in {{language}}, identify if the premise entails, contradicts, or is neutral towards the hypothesis. Please respond with exact 'entailment', 'contradiction', or 'neutral'. \\n\\nPremise: {{premise}} \\nHypothesis: {{hypothesis}}\"\n",
    "prompt_nli = \"Given the following premise and hypothesis in {}, identify if the premise entails, contradicts, or is neutral towards the hypothesis. Please respond with exact 'entailment', 'contradiction', or 'neutral'. \\n\\nPremise: {} \\nHypothesis: {}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e67724dd-7a4b-4f4b-827c-590f32b48922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "\n",
    "import requests\n",
    "url = \"http://localhost:8000/v1/chat/completions\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "def get_gemma3_reply(prompt):\n",
    "    data = {\n",
    "        \"model\": \"google/gemma-3-27b-it\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    completion = response.json()\n",
    "\n",
    "    content = completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return content\n",
    "\n",
    "def get_label(prompt, max_retries=3, backoff_factor=2):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            reply = get_gemma3_reply(prompt)\n",
    "            reply = reply.lower()\n",
    "            # print(reply)\n",
    "            if 'entail' in reply:\n",
    "                label = 0\n",
    "            elif 'neutral' in reply:\n",
    "                label = 1\n",
    "            elif 'contradict' in reply:\n",
    "                label = 2\n",
    "            else:\n",
    "                label = -1\n",
    "\n",
    "            return reply, label\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed with error: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                sleep_time = backoff_factor ** attempt\n",
    "                print(f\"Retrying in {sleep_time} seconds...\")\n",
    "                time.sleep(sleep_time)\n",
    "            else:\n",
    "                print(\"Max retries reached. Returning failure label.\")\n",
    "                return \"\", -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed795787-949b-4fca-8bc8-8f6d3f996185",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_to_run = language_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc4d3390-fc44-485b-91a1-1953fdcae0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [03:48<00:00,  2.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "labels = {}\n",
    "gpt_replies = {}\n",
    "result_accuracies = {}\n",
    "result_inaccuracies = {}\n",
    "\n",
    "for language_code in languages_to_run:\n",
    "    # if language_code == 'eng':\n",
    "    #     continue\n",
    "    print(language_code)\n",
    "    labels[language_code]=[]\n",
    "    gpt_replies[language_code]=[]\n",
    "    result_accuracies[language_code] = 0\n",
    "    result_inaccuracies[language_code] = 0\n",
    "\n",
    "    accurate = 0\n",
    "    errors = 0\n",
    "    df = pd.read_csv(\"nli_dataset/{}/test.csv\".format(language_code))\n",
    "    \n",
    "    for i in tqdm(range(600)): #length of devtest\n",
    "        premise = df.iloc[i]['premise']\n",
    "        hypothesis = df.iloc[i]['hypothesis']\n",
    "        gold_label = df.iloc[i]['label']\n",
    "        \n",
    "        prompt = prompt_nli.format(lang_code_to_name[language_code],premise,hypothesis)\n",
    "        gpt_reply, label = get_label(prompt)\n",
    "        gpt_replies[language_code].append(gpt_reply)\n",
    "        labels[language_code].append(label)\n",
    "        if label == gold_label:\n",
    "            accurate+=1\n",
    "        if label == -1:\n",
    "            errors +=1\n",
    "            \n",
    "    result_accuracies[language_code] = accurate\n",
    "    result_inaccuracies[language_code] = errors\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "    \"premise\": df['premise'],\n",
    "    \"hypothesis\": df['hypothesis'],\n",
    "    \"gpt_label\": labels[language_code]\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    result_df.to_csv(\"nli_predicted_labels_gemma3/{}.csv\".format(language_code), index=False)\n",
    "\n",
    "    df_gpt_replies = pd.DataFrame({\n",
    "        \"premise\": df['premise'],\n",
    "        \"hypothesis\": df['hypothesis'],\n",
    "        \"gpt_reply\": gpt_replies[language_code]\n",
    "    })\n",
    "\n",
    "    df_gpt_replies.to_csv(\"nli_replies_gemma3/{}.csv\".format(language_code), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "117f9b19-3e81-4537-9a96-b20f26520f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"result_accuracies_nli_gemma3.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(result_accuracies, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "with open(\"result_inaccuracies_nli_gemma3.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(result_inaccuracies, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Language name\": [lang_code_to_name[language_code] for language_code in language_codes],\n",
    "    \"Language code\": language_codes,\n",
    "    \"Accuracy\": [round(result_accuracies[language_code]*100/600, 1) for language_code in language_codes]\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"nli_results_gemma3_april2025.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32f321f6-371f-4cae-b99e-3305eba938ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_lang_codes = {\n",
    "    'XNLI': [\n",
    "        'eng', 'fra', 'spa', 'deu', 'ell', 'bul', 'rus', 'tur',\n",
    "        'ara', 'vie', 'tha', 'zho', 'hin', 'swa', 'urd'\n",
    "    ],\n",
    "    'AfriXNLI': [\n",
    "        # West Africa\n",
    "        'ewe', 'hau', 'ibo', 'twi', 'wol', 'yor',\n",
    "        # East Africa\n",
    "        'amh', 'kin', 'lug', 'swa', 'orm',\n",
    "        # Southern Africa\n",
    "        'sna', 'xho', 'zul', 'sot',\n",
    "        # Central Africa\n",
    "        'lin'\n",
    "    ],\n",
    "    'IndicXNLI': [\n",
    "        'asm', 'guj', 'kan', 'mal', 'mar', 'ori', 'pan',\n",
    "        'tam', 'tel', 'hin', 'ben'\n",
    "    ],\n",
    "    'AmericasXNLI': [\n",
    "        'aym', 'cni', 'bzd', 'grn', 'nah', 'oto', 'quy', 'tar', 'shp', 'hch'\n",
    "    ],\n",
    "    'XNLI-ca': ['cat'],\n",
    "    'myXNLI': ['mya'],\n",
    "    'IndoNLI': ['ind'],\n",
    "    'JNLI': ['jpn'],\n",
    "    'Portugese': ['por'],\n",
    "    'Polish': ['pol'],\n",
    "    'JamPatoisNLI': ['pat'],\n",
    "    'Korean': ['kor'],\n",
    "    'Romainian': ['ron']\n",
    "}\n",
    "#create dataset to average performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6d7ed6b-ba2f-4160-8720-8839d220a0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Dataset  Average Accuracy\n",
      "0           XNLI              76.9\n",
      "1       AfriXNLI              64.2\n",
      "2      IndicXNLI              72.0\n",
      "3   AmericasXNLI              42.8\n",
      "4        XNLI-ca              81.2\n",
      "5         myXNLI              73.5\n",
      "6        IndoNLI              81.2\n",
      "7           JNLI              70.8\n",
      "8      Portugese              95.7\n",
      "9         Polish              81.2\n",
      "10  JamPatoisNLI              87.3\n",
      "11        Korean              81.7\n",
      "12     Romainian              67.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df, lang_code_to_name, result_accuracies, language_codes, and dataset_to_lang_codes are already defined\n",
    "\n",
    "# Create a mapping from language code to accuracy for fast lookup\n",
    "lang_code_to_accuracy = dict(zip(df[\"Language code\"], df[\"Accuracy\"]))\n",
    "\n",
    "# Compute average accuracy per dataset\n",
    "dataset_avg_accuracies = {}\n",
    "\n",
    "for dataset, lang_codes in dataset_to_lang_codes.items():\n",
    "    # Filter to only those lang codes that are in df\n",
    "    valid_langs = [code for code in lang_codes if code in lang_code_to_accuracy]\n",
    "    \n",
    "    if valid_langs:\n",
    "        scores = [lang_code_to_accuracy[code] for code in valid_langs]\n",
    "        avg_accuracy = round(sum(scores) / len(scores), 1)\n",
    "        dataset_avg_accuracies[dataset] = avg_accuracy\n",
    "\n",
    "# Convert to a DataFrame if desired\n",
    "dataset_avg_df = pd.DataFrame.from_dict(dataset_avg_accuracies, orient='index', columns=['Average Accuracy']).reset_index()\n",
    "dataset_avg_df = dataset_avg_df.rename(columns={'index': 'Dataset'})\n",
    "\n",
    "print(dataset_avg_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07bb5af6-fc8a-4099-b6f5-fb4a5a49083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_avg_df.to_csv('nli_results_gemma3_april2025_by_family.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc43899-07dd-4426-8bd0-a28adc6b38b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
