{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd7909a-67c7-480b-abdc-a76bfd3e8076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bjn_Latn': 56.9, 'lus_Latn': 35.9, 'pbt_Arab': 57.9, 'spa_Latn': 56.1, 'som_Latn': 53.8, 'pes_Arab': 61.8, 'gle_Latn': 64.8, 'szl_Latn': 64.9, 'zho_Hans': 56.2, 'kam_Latn': 34.3, 'dyu_Latn': 24.9, 'zul_Latn': 59.9, 'ron_Latn': 66.6, 'nno_Latn': 68.2, 'san_Deva': 46.8, 'xho_Latn': 59.4, 'hye_Armn': 64.0, 'hun_Latn': 61.5, 'lao_Laoo': 57.4, 'urd_Arab': 60.6, 'slv_Latn': 61.1, 'pag_Latn': 47.0, 'zho_Hant': 55.0, 'tzm_Tfng': 18.5, 'nob_Latn': 67.3, 'gaz_Latn': 46.9, 'isl_Latn': 60.8, 'arb_Arab': 64.2, 'mri_Latn': 53.3, 'sun_Latn': 61.9, 'asm_Beng': 55.1, 'yue_Hant': 57.2, 'hrv_Latn': 63.6, 'lug_Latn': 47.4, 'bem_Latn': 38.8, 'grn_Latn': 46.0, 'khm_Khmr': 55.2, 'taq_Latn': 26.4, 'ckb_Arab': 51.3, 'afr_Latn': 77.0, 'mos_Latn': 23.6, 'min_Arab': 41.8, 'lin_Latn': 45.6, 'sna_Latn': 49.0, 'cym_Latn': 76.5, 'ory_Orya': 58.3, 'ita_Latn': 58.6, 'ban_Latn': 54.8, 'zsm_Latn': 68.1, 'bod_Tibt': 30.9, 'ibo_Latn': 51.1, 'kaz_Cyrl': 60.6, 'jpn_Jpan': 54.6, 'smo_Latn': 55.1, 'npi_Deva': 65.1, 'snd_Arab': 62.9, 'jav_Latn': 63.7, 'tgk_Cyrl': 59.3, 'ell_Grek': 60.3, 'ayr_Latn': 30.4, 'bak_Cyrl': 56.3, 'uig_Arab': 50.8, 'kin_Latn': 54.6, 'acm_Arab': 59.4, 'kas_Deva': 42.6, 'lua_Latn': 31.3, 'kbp_Latn': 22.4, 'ace_Latn': 44.3, 'ceb_Latn': 66.7, 'als_Latn': 64.6, 'fra_Latn': 67.7, 'nus_Latn': 21.4, 'guj_Gujr': 63.5, 'tat_Cyrl': 57.5, 'knc_Latn': 25.8, 'ssw_Latn': 48.3, 'nya_Latn': 49.9, 'yor_Latn': 45.0, 'pan_Guru': 61.8, 'sin_Sinh': 57.5, 'ast_Latn': 65.2, 'srd_Latn': 63.9, 'sot_Latn': 58.5, 'fin_Latn': 60.7, 'amh_Ethi': 53.6, 'kon_Latn': 39.4, 'kmr_Latn': 48.6, 'uzn_Latn': 60.0, 'bul_Cyrl': 66.3, 'kir_Cyrl': 52.4, 'bos_Latn': 66.7, 'aka_Latn': 39.0, 'fur_Latn': 62.9, 'ltg_Latn': 58.7, 'tsn_Latn': 49.2, 'war_Latn': 68.0, 'tso_Latn': 50.4, 'ajp_Arab': 65.3, 'khk_Cyrl': 57.3, 'fon_Latn': 21.7, 'cjk_Latn': 25.7, 'sat_Olck': 17.7, 'cat_Latn': 69.0, 'ind_Latn': 68.0, 'mai_Deva': 63.1, 'plt_Latn': 54.5, 'arz_Arab': 57.2, 'taq_Tfng': 18.2, 'arb_Latn': 57.8, 'run_Latn': 45.6, 'eus_Latn': 58.4, 'lim_Latn': 64.7, 'kan_Knda': 57.5, 'ydd_Hebr': 73.3, 'bel_Cyrl': 49.1, 'bam_Latn': 27.2, 'vec_Latn': 65.9, 'prs_Arab': 63.2, 'tuk_Latn': 59.9, 'tgl_Latn': 68.3, 'fij_Latn': 42.5, 'nld_Latn': 57.8, 'luo_Latn': 35.1, 'mar_Deva': 61.9, 'min_Latn': 57.4, 'umb_Latn': 26.6, 'kas_Arab': 46.9, 'ewe_Latn': 27.1, 'lmo_Latn': 62.0, 'wol_Latn': 40.5, 'kik_Latn': 38.6, 'mlt_Latn': 74.4, 'kmb_Latn': 25.4, 'hne_Deva': 63.5, 'mkd_Cyrl': 66.3, 'kat_Geor': 56.1, 'rus_Cyrl': 60.8, 'aeb_Arab': 57.5, 'bjn_Arab': 42.7, 'tam_Taml': 57.4, 'fao_Latn': 62.6, 'slk_Latn': 64.6, 'deu_Latn': 67.5, 'awa_Deva': 60.1, 'mya_Mymr': 51.8, 'kor_Hang': 57.5, 'apc_Arab': 62.7, 'twi_Latn': 41.4, 'ces_Latn': 65.2, 'hat_Latn': 64.0, 'hau_Latn': 56.0, 'glg_Latn': 65.1, 'swe_Latn': 70.2, 'mni_Beng': 30.9, 'ben_Beng': 60.2, 'fuv_Latn': 27.7, 'pap_Latn': 69.1, 'mag_Deva': 64.7, 'vie_Latn': 60.9, 'acq_Arab': 61.2, 'oci_Latn': 74.1, 'dik_Latn': 25.8, 'lvs_Latn': 61.7, 'shn_Mymr': 22.9, 'est_Latn': 63.7, 'kac_Latn': 23.7, 'kab_Latn': 29.0, 'sag_Latn': 24.9, 'swh_Latn': 66.9, 'ary_Arab': 56.3, 'azj_Latn': 50.6, 'tur_Latn': 63.4, 'bug_Latn': 36.5, 'por_Latn': 71.1, 'azb_Arab': 46.5, 'ars_Arab': 63.1, 'mal_Mlym': 60.4, 'gla_Latn': 60.0, 'kea_Latn': 69.7, 'hin_Deva': 64.7, 'tpi_Latn': 49.3, 'srp_Cyrl': 67.6, 'crh_Latn': 54.5, 'lit_Latn': 60.2, 'tha_Thai': 57.5, 'dan_Latn': 70.3, 'tel_Telu': 62.9, 'scn_Latn': 62.7, 'lij_Latn': 63.6, 'ltz_Latn': 69.7, 'ilo_Latn': 55.3, 'tir_Ethi': 35.5, 'tum_Latn': 39.4, 'ukr_Cyrl': 64.8, 'pol_Latn': 56.8, 'epo_Latn': 67.7, 'ace_Arab': 34.5, 'nso_Latn': 59.2, 'heb_Hebr': 67.2, 'quy_Latn': 31.3, 'bho_Deva': 53.5, 'knc_Arab': 20.5, 'dzo_Tibt': 26.8}\n"
     ]
    }
   ],
   "source": [
    "#get scores \n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "# Define paths\n",
    "translations_dir = \"translations_gpt4o_xx_eng2\"\n",
    "reference_file = \"reference_xx_eng/eng_Latn.txt\"\n",
    "\n",
    "# Dictionary to store scores\n",
    "scores = {}\n",
    "\n",
    "# Loop over all .txt files in the translations directory\n",
    "for file in os.listdir(translations_dir):\n",
    "    if file.endswith(\".txt\"):  # Process only .txt files\n",
    "        language_name = file.replace(\".txt\", \"\")  # Extract language name\n",
    "        translation_file = os.path.join(translations_dir, file)  # Full path\n",
    "\n",
    "        # Run sacrebleu command\n",
    "        command = f\"sacrebleu -m chrf --chrf-word-order 2 {translation_file} < {reference_file}\"\n",
    "        result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "        # Extract the score from the output\n",
    "        try:\n",
    "            output_json = json.loads(result.stdout)  # Parse JSON output\n",
    "            scores[language_name] = output_json[\"score\"]  # Store score\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error processing {language_name}: Invalid JSON output\")\n",
    "        except KeyError:\n",
    "            print(f\"Error: 'score' field not found in {language_name} output\")\n",
    "\n",
    "# Print results\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2bcf487-ba26-43c0-8369-3c9d3c3a7ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bjn_Latn': 38.0, 'lus_Latn': 29.5, 'pbt_Arab': 35.1, 'spa_Latn': 56.6, 'som_Latn': 41.4, 'pes_Arab': 52.3, 'gle_Latn': 57.0, 'szl_Latn': 38.7, 'zho_Hans': 33.1, 'kam_Latn': 23.6, 'dyu_Latn': 16.5, 'zul_Latn': 48.3, 'ron_Latn': 65.8, 'nno_Latn': 61.5, 'san_Deva': 26.0, 'xho_Latn': 44.5, 'hye_Armn': 53.2, 'hun_Latn': 57.0, 'lao_Laoo': 35.8, 'urd_Arab': 47.7, 'slv_Latn': 58.4, 'pag_Latn': 28.5, 'zho_Hant': 27.3, 'tzm_Tfng': 3.2, 'nob_Latn': 60.9, 'gaz_Latn': 32.1, 'isl_Latn': 53.5, 'arb_Arab': 55.9, 'mri_Latn': 47.9, 'sun_Latn': 47.6, 'asm_Beng': 34.3, 'yue_Hant': 22.3, 'hrv_Latn': 59.2, 'lug_Latn': 32.7, 'bem_Latn': 28.6, 'grn_Latn': 28.1, 'khm_Khmr': 29.2, 'taq_Latn': 18.4, 'ckb_Arab': 28.8, 'afr_Latn': 67.6, 'mos_Latn': 16.6, 'min_Arab': 15.6, 'lin_Latn': 42.3, 'sna_Latn': 43.1, 'cym_Latn': 70.0, 'ory_Orya': 36.4, 'ita_Latn': 60.1, 'ban_Latn': 35.8, 'zsm_Latn': 67.0, 'bod_Tibt': 18.2, 'ibo_Latn': 38.4, 'kaz_Cyrl': 52.0, 'jpn_Jpan': 35.5, 'smo_Latn': 49.1, 'npi_Deva': 47.7, 'snd_Arab': 44.4, 'jav_Latn': 53.3, 'tgk_Cyrl': 49.4, 'ell_Grek': 54.7, 'ayr_Latn': 23.8, 'bak_Cyrl': 46.4, 'uig_Arab': 31.2, 'kin_Latn': 46.1, 'acm_Arab': 45.2, 'kas_Deva': 13.9, 'lua_Latn': 22.2, 'kbp_Latn': 14.0, 'ace_Latn': 29.0, 'ceb_Latn': 58.1, 'als_Latn': 60.3, 'fra_Latn': 71.5, 'nus_Latn': 14.0, 'guj_Gujr': 39.3, 'tat_Cyrl': 48.8, 'knc_Latn': 19.1, 'ssw_Latn': 35.1, 'nya_Latn': 44.0, 'yor_Latn': 22.4, 'pan_Guru': 42.6, 'sin_Sinh': 31.3, 'ast_Latn': 54.9, 'srd_Latn': 42.4, 'sot_Latn': 48.0, 'fin_Latn': 58.4, 'amh_Ethi': 23.8, 'kon_Latn': 29.2, 'kmr_Latn': 29.1, 'uzn_Latn': 51.9, 'bul_Cyrl': 65.6, 'kir_Cyrl': 45.1, 'bos_Latn': 61.8, 'aka_Latn': 27.9, 'fur_Latn': 44.4, 'ltg_Latn': 29.6, 'tsn_Latn': 43.7, 'war_Latn': 55.2, 'tso_Latn': 41.2, 'ajp_Arab': 48.8, 'khk_Cyrl': 46.7, 'fon_Latn': 13.7, 'cjk_Latn': 19.4, 'sat_Olck': 1.1, 'cat_Latn': 67.0, 'ind_Latn': 69.7, 'mai_Deva': 40.3, 'plt_Latn': 49.0, 'arz_Arab': 45.9, 'taq_Tfng': 11.4, 'arb_Latn': 29.7, 'run_Latn': 37.1, 'eus_Latn': 52.0, 'lim_Latn': 37.8, 'kan_Knda': 41.0, 'ydd_Hebr': 33.6, 'bel_Cyrl': 45.2, 'bam_Latn': 19.1, 'vec_Latn': 43.5, 'prs_Arab': 46.3, 'tuk_Latn': 48.6, 'tgl_Latn': 63.4, 'fij_Latn': 41.7, 'nld_Latn': 57.0, 'luo_Latn': 30.3, 'mar_Deva': 45.6, 'min_Latn': 41.9, 'umb_Latn': 21.2, 'kas_Arab': 18.5, 'ewe_Latn': 20.7, 'lmo_Latn': 32.1, 'wol_Latn': 23.1, 'kik_Latn': 24.9, 'mlt_Latn': 66.4, 'kmb_Latn': 20.4, 'hne_Deva': 34.5, 'mkd_Cyrl': 62.3, 'kat_Geor': 48.4, 'rus_Cyrl': 58.4, 'aeb_Arab': 41.7, 'bjn_Arab': 13.6, 'tam_Taml': 30.2, 'fao_Latn': 49.5, 'slk_Latn': 60.1, 'deu_Latn': 66.0, 'awa_Deva': 33.1, 'mya_Mymr': 32.6, 'kor_Hang': 37.4, 'apc_Arab': 47.8, 'twi_Latn': 29.1, 'ces_Latn': 59.4, 'hat_Latn': 53.4, 'hau_Latn': 49.0, 'glg_Latn': 62.7, 'swe_Latn': 69.3, 'mni_Beng': 11.3, 'ben_Beng': 46.5, 'fuv_Latn': 17.6, 'pap_Latn': 51.1, 'mag_Deva': 40.0, 'vie_Latn': 61.3, 'acq_Arab': 48.7, 'oci_Latn': 62.7, 'dik_Latn': 16.0, 'lvs_Latn': 60.2, 'shn_Mymr': 15.5, 'est_Latn': 58.3, 'kac_Latn': 24.3, 'kab_Latn': 20.7, 'sag_Latn': 21.6, 'swh_Latn': 62.1, 'ary_Arab': 37.7, 'azj_Latn': 44.6, 'tur_Latn': 59.6, 'bug_Latn': 23.8, 'por_Latn': 71.7, 'azb_Arab': 5.4, 'ars_Arab': 47.5, 'mal_Mlym': 39.8, 'gla_Latn': 50.1, 'kea_Latn': 46.9, 'hin_Deva': 53.4, 'tpi_Latn': 46.1, 'srp_Cyrl': 2.6, 'crh_Latn': 32.3, 'lit_Latn': 56.4, 'tha_Thai': 49.5, 'dan_Latn': 70.6, 'tel_Telu': 44.3, 'scn_Latn': 41.0, 'lij_Latn': 35.1, 'ltz_Latn': 56.5, 'ilo_Latn': 42.9, 'tir_Ethi': 10.4, 'tum_Latn': 35.5, 'ukr_Cyrl': 58.0, 'pol_Latn': 51.6, 'epo_Latn': 60.8, 'ace_Arab': 12.4, 'nso_Latn': 47.9, 'heb_Hebr': 59.0, 'quy_Latn': 26.3, 'bho_Deva': 33.0, 'knc_Arab': 6.8, 'dzo_Tibt': 17.8}\n"
     ]
    }
   ],
   "source": [
    "#get scores2 for eng to xx\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "# Define paths\n",
    "translations_dir = \"translations_gpt4o_eng_xx2\"\n",
    "reference_dir = \"reference_eng_xx\"\n",
    "\n",
    "# Dictionary to store scores2\n",
    "scores2 = {}\n",
    "\n",
    "# Loop over all .txt files in the translations directory\n",
    "for file in os.listdir(translations_dir):\n",
    "    if file.endswith(\".txt\"):  # Process only .txt files\n",
    "        language_name = file.replace(\".txt\", \"\")  # Extract language name\n",
    "        translation_file = os.path.join(translations_dir, file)  # Full path\n",
    "        reference_file = os.path.join(reference_dir, file)  # Full path\n",
    "\n",
    "        # Run sacrebleu command\n",
    "        command = f\"sacrebleu -m chrf --chrf-word-order 2 {translation_file} < {reference_file}\"\n",
    "        result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "        # Extract the score from the output\n",
    "        try:\n",
    "            output_json = json.loads(result.stdout)  # Parse JSON output\n",
    "            scores2[language_name] = output_json[\"score\"]  # Store score\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error processing {language_name}: Invalid JSON output\")\n",
    "        except KeyError:\n",
    "            print(f\"Error: 'score' field not found in {language_name} output\")\n",
    "\n",
    "# Print results\n",
    "print(scores2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b674f328-47f1-44a7-9149-28e9978d2be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "language_mapping = pd.read_csv('language_mapping.csv')\n",
    "language_mapping_index = language_mapping.set_index('FLORES-200 code')['Language'].to_dict()\n",
    "# Convert to DataFrame\n",
    "all_languages = list(language_mapping_index.keys())\n",
    "all_languages.remove('eng_Latn')\n",
    "\n",
    "all_languages2 = list(language_mapping_index.values())\n",
    "all_languages2.remove('English')\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Language\": all_languages2,\n",
    "    \"FLORES-200 code\": all_languages,\n",
    "    \"xx - English\": [scores[lang] for lang in all_languages],\n",
    "    \"English - xx\": [scores2[lang] for lang in all_languages]\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"flores_gpt4o_results_april_2025_prompt2.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28991902-ccf3-4c07-9dd1-55dacb548d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "language_mapping = pd.read_csv('language_mapping.csv')\n",
    "language_mapping_index = language_mapping.set_index('FLORES-200 code')['Language'].to_dict()\n",
    "flores_languages = list(language_mapping_index.keys())\n",
    "\n",
    "# Convert to DataFrame\n",
    "all_languages = list(language_mapping_index.keys()) #code\n",
    "\n",
    "all_languages2 = list(language_mapping_index.values()) #name\n",
    "\n",
    "import bisect\n",
    "# New elements to insert\n",
    "new_key = \"nqo_Nkoo\"\n",
    "new_value = \"N'ko\"\n",
    "\n",
    "# Find the correct index to insert while maintaining sorted order\n",
    "index = bisect.bisect(all_languages, new_key)\n",
    "\n",
    "# Insert in both lists at the correct position\n",
    "all_languages.insert(index, new_key)\n",
    "all_languages2.insert(index, new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab00e5b1-2b47-4e93-8b5c-bb356f9cdbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flores_df = pd.read_csv('flores_gpt4o_results_april_2025_prompt2.csv')\n",
    "old_results_df = pd.read_csv('old_results.csv')\n",
    "sib_df = pd.read_csv('sib_gpt4o_results_april2025_prompt2.csv')\n",
    "\n",
    "lang_family = old_results_df.set_index('language_code')['language_family'].to_dict()\n",
    "lang_family_array = []\n",
    "for lang in all_languages:\n",
    "    if lang in lang_family.keys():\n",
    "        lang_family_array.append(lang_family[lang])\n",
    "    else:\n",
    "        lang_family_array.append('')\n",
    "\n",
    "sib_scores = sib_df.set_index('Language code')['Accuracy'].to_dict()\n",
    "sib_array = []\n",
    "for lang in all_languages:\n",
    "    if lang in sib_scores.keys():\n",
    "        sib_array.append(sib_scores[lang])\n",
    "    else:\n",
    "        sib_array.append('')\n",
    "\n",
    "flores_xx_eng_scores = flores_df.set_index('FLORES-200 code')['xx - English'].to_dict()\n",
    "flores_xx_eng_array = []\n",
    "for lang in all_languages:\n",
    "    if lang in flores_xx_eng_scores.keys():\n",
    "        flores_xx_eng_array.append(flores_xx_eng_scores[lang])\n",
    "    else:\n",
    "        flores_xx_eng_array.append('')\n",
    "\n",
    "flores_eng_xx_scores = flores_df.set_index('FLORES-200 code')['English - xx'].to_dict()\n",
    "flores_eng_xx_array = []\n",
    "for lang in all_languages:\n",
    "    if lang in flores_eng_xx_scores.keys():\n",
    "        flores_eng_xx_array.append(flores_eng_xx_scores[lang])\n",
    "    else:\n",
    "        flores_eng_xx_array.append('')\n",
    "        \n",
    "result_df = pd.DataFrame({\n",
    "    \"language_name\": all_languages2,\n",
    "    \"language_code\": all_languages,\n",
    "    \"language_family\": lang_family_array,\n",
    "    \"SIB gpt-4o (Apr 2025)\": sib_array,\n",
    "    \"Flores xx-eng gpt-4o (Apr 2025)\": flores_xx_eng_array,\n",
    "    \"Flores eng-xx gpt-4o (Apr 2025)\": flores_eng_xx_array\n",
    "\n",
    "})\n",
    "\n",
    "result_df.to_csv('overall_results_gpt4o.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e188090-9d43-43b7-b25b-d0a143274b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('overall_results_gpt4o.csv')\n",
    "z=df2.groupby('language_family') \\\n",
    "       .agg({'language_name':'size','SIB gpt-4o (Apr 2025)':'mean','Flores xx-eng gpt-4o (Apr 2025)':'mean','Flores eng-xx gpt-4o (Apr 2025)':'mean'} ) \\\n",
    "       .rename(columns={'language_name':'count'}) \\\n",
    "       .sort_values(by=['count'], ascending=False) \\\n",
    "       .reset_index().round(1)\n",
    "z.to_csv('overall_by_family_gpt4o.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac34f4-a537-4494-9c33-7e08141279a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
