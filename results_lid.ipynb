{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e191e40c-4da1-42e6-a79b-f35d59b35fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56b4f87a-bac0-43ce-a64b-3ea1c5102300",
   "metadata": {},
   "outputs": [],
   "source": [
    "flores_l = {'afr_Latn': 'Afrikaans',\n",
    " 'amh_Ethi': 'Amharic',\n",
    " 'arb_Arab': 'Arabic',\n",
    " 'asm_Beng': 'Assamese',\n",
    " 'ast_Latn': 'Asturian',\n",
    " 'azj_Latn': 'Azerbaijani',\n",
    " 'bel_Cyrl': 'Belarusian',\n",
    " 'ben_Beng': 'Bengali',\n",
    " 'bos_Latn': 'Bosnian',\n",
    " 'bul_Cyrl': 'Bulgarian',\n",
    " 'cat_Latn': 'Catalan',\n",
    " 'ceb_Latn': 'Cebuano',\n",
    " 'ces_Latn': 'Czech',\n",
    " 'ckb_Arab': 'Kurdish',\n",
    " 'cym_Latn': 'Welsh',\n",
    " 'dan_Latn': 'Danish',\n",
    " 'deu_Latn': 'German',\n",
    " 'ell_Grek': 'Greek',\n",
    " 'eng_Latn': 'English',\n",
    " 'est_Latn': 'Estonian',\n",
    " 'fin_Latn': 'Finnish',\n",
    " 'fra_Latn': 'French',\n",
    " 'gaz_Latn': 'Oromo',\n",
    " 'gle_Latn': 'Irish',\n",
    " 'glg_Latn': 'Galician',\n",
    " 'guj_Gujr': 'Gujarati',\n",
    " 'hau_Latn': 'Hausa',\n",
    " 'heb_Hebr': 'Hebrew',\n",
    " 'hin_Deva': 'Hindi',\n",
    " 'hrv_Latn': 'Croatian',\n",
    " 'hun_Latn': 'Hungarian',\n",
    " 'hye_Armn': 'Armenian',\n",
    " 'ibo_Latn': 'Igbo',\n",
    " 'ind_Latn': 'Indonesian',\n",
    " 'isl_Latn': 'Icelandic',\n",
    " 'ita_Latn': 'Italian',\n",
    " 'jav_Latn': 'Javanese',\n",
    " 'jpn_Jpan': 'Japanese',\n",
    " 'kam_Latn': 'Kamba',\n",
    " 'kan_Knda': 'Kannada',\n",
    " 'kat_Geor': 'Georgian',\n",
    " 'kaz_Cyrl': 'Kazakh',\n",
    " 'kea_Latn': 'Kabuverdianu',\n",
    " 'khk_Cyrl': 'Mongolian',\n",
    " 'khm_Khmr': 'Khmer',\n",
    " 'kor_Hang': 'Korean',\n",
    " 'lao_Laoo': 'Lao',\n",
    " 'lin_Latn': 'Lingala',\n",
    " 'lit_Latn': 'Lithuanian',\n",
    " 'ltz_Latn': 'Luxembourgish',\n",
    " 'lug_Latn': 'Ganda',\n",
    " 'luo_Latn': 'Luo',\n",
    " 'lvs_Latn': 'Latvian',\n",
    " 'mal_Mlym': 'Malayalam',\n",
    " 'mar_Deva': 'Marathi',\n",
    " 'mkd_Cyrl': 'Macedonian',\n",
    " 'mlt_Latn': 'Maltese',\n",
    " 'mri_Latn': 'Maori',\n",
    " 'mya_Mymr': 'Burmese',\n",
    " 'nld_Latn': 'Dutch',\n",
    " 'nob_Latn': 'Norwegian',\n",
    " 'npi_Deva': 'Nepali',\n",
    " 'nso_Latn': 'Sotho',\n",
    " 'nya_Latn': 'Nyanja',\n",
    " 'oci_Latn': 'Occitan',\n",
    " 'ory_Orya': 'Odia',\n",
    " 'pan_Guru': 'Punjabi',\n",
    " 'pbt_Arab': 'Pashto',\n",
    " 'pes_Arab': 'Persian',\n",
    " 'pol_Latn': 'Polish',\n",
    " 'por_Latn': 'Portuguese',\n",
    " 'ron_Latn': 'Romanian',\n",
    " 'rus_Cyrl': 'Russian',\n",
    " 'slk_Latn': 'Slovak',\n",
    " 'slv_Latn': 'Slovenian',\n",
    " 'smo_Latn': 'Samoan',\n",
    " 'sna_Latn': 'Shona',\n",
    " 'snd_Arab': 'Sindhi',\n",
    " 'som_Latn': 'Somali',\n",
    " 'spa_Latn': 'Spanish',\n",
    " 'srp_Cyrl': 'Serbian',\n",
    " 'swe_Latn': 'Swedish',\n",
    " 'swh_Latn': 'Swahili',\n",
    " 'tam_Taml': 'Tamil',\n",
    " 'tel_Telu': 'Telugu',\n",
    " 'tgk_Cyrl': 'Tajik',\n",
    " 'tgl_Latn': 'Tagalog',\n",
    " 'tha_Thai': 'Thai',\n",
    " 'tur_Latn': 'Turkish',\n",
    " 'ukr_Cyrl': 'Ukrainian',\n",
    " 'umb_Latn': 'Umbundu',\n",
    " 'urd_Arab': 'Urdu',\n",
    " 'uzn_Latn': 'Uzbek',\n",
    " 'vie_Latn': 'Vietnamese',\n",
    " 'wol_Latn': 'Wolof',\n",
    " 'xho_Latn': 'Xhosa',\n",
    " 'yor_Latn': 'Yoruba',\n",
    " 'zho_Hans': 'Chinese',\n",
    " 'zho_Hant': 'Chinese',\n",
    " 'zsm_Latn': 'Malay',\n",
    " 'zul_Latn': 'Zulu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3f46704-36b3-4e24-a19d-1a364b95275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "redo_l = {\n",
    " 'arb_Arab': ['Arabic','العربية'],\n",
    " 'asm_Beng': ['Assamese','অসমীয়া'],\n",
    " 'bos_Latn': ['Bosnian','Croatian','Serbian'],\n",
    " 'kea_Latn': ['Kabuverdianu','Creole','Kriol'],\n",
    " 'mri_Latn': ['Maori','Māori'],\n",
    " 'nso_Latn': ['Sotho','Sepedi','Setswana'],\n",
    " 'nya_Latn': ['Nyanja','Chewa'],\n",
    " 'slv_Latn': ['Slovenian','Slovene'],\n",
    " 'tgl_Latn': ['Tagalog','Filipino'],\n",
    " 'zho_Hant': ['Chinese']\n",
    "}\n",
    "redo_languages = list(redo_l.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28b4235e-f441-4317-8512-93e99e2f6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo those with valid reasons\n",
    "reply_dir_gpt = \"lid_replies_gpt4o\"\n",
    "reply_dir_gemini = \"lid_replies_gemini2\"\n",
    "reply_dir_gemma = \"lid_replies_gemma3\"\n",
    "\n",
    "for language_code in redo_languages':\n",
    "    correct_answers = redo_l[language_code]\n",
    "    result_list = []\n",
    "    \n",
    "    reply_path = os.path.join(reply_dir_gpt, \"{}.csv\".format(language_code))\n",
    "    df = pd.read_csv(reply_path)\n",
    "\n",
    "    for i in range(1012):\n",
    "        reply = df['gpt_reply'][i]\n",
    "        result = \"invalid\"\n",
    "        for correct_answer in correct_answers: #any answer matches it's a match. \n",
    "            if correct_answer.lower() in reply.lower():\n",
    "                result = flores_l[language_code]\n",
    "                break\n",
    "        result_list.append(result)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "    \"gpt_answer\": result_list\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(\"lid_predicted_gpt4o/{}.csv\".format(language_code), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0faa68d-9204-4be9-a3d7-b697b9354a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for language_code in redo_languages:\n",
    "    correct_answers = redo_l[language_code]\n",
    "    result_list = []\n",
    "    \n",
    "    reply_path = os.path.join(reply_dir_gemini, \"{}.csv\".format(language_code))\n",
    "    df = pd.read_csv(reply_path)\n",
    "\n",
    "    for i in range(1012):\n",
    "        reply = df['gemini_reply'][i]\n",
    "        result = \"invalid\"\n",
    "        for correct_answer in correct_answers: #any answer matches it's a match. \n",
    "            if correct_answer.lower() in reply.lower():\n",
    "                result = flores_l[language_code]\n",
    "                break\n",
    "        result_list.append(result)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "    \"gemini_answer\": result_list\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(\"lid_predicted_gemini2/{}.csv\".format(language_code), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe73bd38-5d62-4701-b04f-8229d1436c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for language_code in redo_languages:\n",
    "    correct_answers = redo_l[language_code]\n",
    "    result_list = []\n",
    "    \n",
    "    reply_path = os.path.join(reply_dir_gemma, \"{}.csv\".format(language_code))\n",
    "    df = pd.read_csv(reply_path)\n",
    "\n",
    "    for i in range(1012):\n",
    "        reply = df['gemma3_reply'][i]\n",
    "        result = \"invalid\"\n",
    "        for correct_answer in correct_answers: #any answer matches it's a match. \n",
    "            if correct_answer.lower() in reply.lower():\n",
    "                result = flores_l[language_code]\n",
    "                break\n",
    "        result_list.append(result)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "    \"gemma3_answer\": result_list\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(\"lid_predicted_gemma3/{}.csv\".format(language_code), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a7361f3-8d3b-46b0-bde0-6a3c07fe4d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_languages = list(flores_l.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d48466ef-4c1d-489e-8a0c-aab6de9544af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mar_Deva': 1009, 'umb_Latn': 400, 'wol_Latn': 1009, 'mlt_Latn': 1012, 'kan_Knda': 996, 'bel_Cyrl': 939, 'tgl_Latn': 1012, 'luo_Latn': 1000, 'nld_Latn': 1011, 'ces_Latn': 1010, 'hau_Latn': 1012, 'glg_Latn': 986, 'swe_Latn': 1012, 'ben_Beng': 1011, 'vie_Latn': 1010, 'mkd_Cyrl': 995, 'rus_Cyrl': 1009, 'kat_Geor': 1007, 'slk_Latn': 1012, 'mya_Mymr': 1011, 'deu_Latn': 987, 'tam_Taml': 998, 'kor_Hang': 1012, 'azj_Latn': 1012, 'tur_Latn': 1006, 'por_Latn': 1012, 'kea_Latn': 726, 'mal_Mlym': 1001, 'hin_Deva': 1003, 'tha_Thai': 1006, 'lit_Latn': 1009, 'srp_Cyrl': 1010, 'oci_Latn': 1002, 'lvs_Latn': 1012, 'est_Latn': 1012, 'swh_Latn': 1012, 'heb_Hebr': 988, 'dan_Latn': 1009, 'tel_Telu': 847, 'ltz_Latn': 1010, 'ukr_Cyrl': 1011, 'pol_Latn': 1012, 'nso_Latn': 999, 'zul_Latn': 1007, 'ron_Latn': 1011, 'xho_Latn': 927, 'hye_Armn': 1012, 'hun_Latn': 1012, 'lao_Laoo': 1012, 'pbt_Arab': 1012, 'som_Latn': 1012, 'spa_Latn': 979, 'pes_Arab': 1003, 'gle_Latn': 1000, 'kam_Latn': 523, 'zho_Hans': 1011, 'afr_Latn': 1012, 'ckb_Arab': 1012, 'lin_Latn': 1012, 'sna_Latn': 1012, 'cym_Latn': 1012, 'ory_Orya': 1006, 'zsm_Latn': 978, 'ita_Latn': 1012, 'ibo_Latn': 1011, 'jpn_Jpan': 1012, 'kaz_Cyrl': 1010, 'npi_Deva': 997, 'smo_Latn': 1012, 'zho_Hant': 1012, 'slv_Latn': 1010, 'urd_Arab': 986, 'isl_Latn': 1012, 'nob_Latn': 1010, 'gaz_Latn': 1011, 'mri_Latn': 1012, 'arb_Arab': 1012, 'asm_Beng': 997, 'hrv_Latn': 736, 'lug_Latn': 1009, 'khm_Khmr': 1012, 'pan_Guru': 1010, 'nya_Latn': 1012, 'yor_Latn': 1010, 'ast_Latn': 985, 'fin_Latn': 1012, 'snd_Arab': 1011, 'jav_Latn': 1010, 'tgk_Cyrl': 1004, 'ell_Grek': 1012, 'ceb_Latn': 1011, 'fra_Latn': 963, 'guj_Gujr': 1008, 'khk_Cyrl': 1012, 'cat_Latn': 1012, 'ind_Latn': 998, 'eng_Latn': 1011, 'amh_Ethi': 1012, 'uzn_Latn': 1012, 'bul_Cyrl': 1012, 'bos_Latn': 1012}\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "results_dir_gpt = \"lid_predicted_gpt4o\"\n",
    "results_dir_gemini = \"lid_predicted_gemini2\"\n",
    "results_dir_gemma = \"lid_predicted_gemma3\"\n",
    "\n",
    "scores_gpt = {}\n",
    "scores_gemini = {}\n",
    "scores_gemma = {}\n",
    "\n",
    "for file in os.listdir(results_dir_gpt):\n",
    "    if file.endswith(\".csv\"):  # Process only .txt files\n",
    "        language_code = file.replace(\".csv\", \"\")\n",
    "        correct_answer = flores_l[language_code]\n",
    "        \n",
    "        file_path = os.path.join(results_dir_gpt, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        matches = (df['gpt_answer'] == correct_answer).sum()\n",
    "        scores_gpt[language_code] = matches\n",
    "print(scores_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a364dac5-a8de-48ea-9af9-5ddea3f7a2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mar_Deva': 1010, 'umb_Latn': 770, 'wol_Latn': 1007, 'mlt_Latn': 1011, 'kan_Knda': 1012, 'bel_Cyrl': 1011, 'tgl_Latn': 1011, 'luo_Latn': 1004, 'nld_Latn': 1011, 'ces_Latn': 1011, 'hau_Latn': 1011, 'glg_Latn': 975, 'swe_Latn': 1012, 'ben_Beng': 1012, 'vie_Latn': 1011, 'mkd_Cyrl': 1012, 'rus_Cyrl': 1010, 'kat_Geor': 1012, 'slk_Latn': 1012, 'mya_Mymr': 1012, 'deu_Latn': 1012, 'tam_Taml': 1012, 'kor_Hang': 1012, 'azj_Latn': 1011, 'tur_Latn': 1011, 'por_Latn': 1011, 'kea_Latn': 916, 'mal_Mlym': 1012, 'hin_Deva': 1008, 'tha_Thai': 1012, 'lit_Latn': 1012, 'srp_Cyrl': 1007, 'oci_Latn': 988, 'lvs_Latn': 1012, 'est_Latn': 1012, 'swh_Latn': 1010, 'heb_Hebr': 1012, 'dan_Latn': 999, 'tel_Telu': 1011, 'ltz_Latn': 1011, 'ukr_Cyrl': 1012, 'pol_Latn': 1012, 'nso_Latn': 982, 'zul_Latn': 1007, 'ron_Latn': 1012, 'xho_Latn': 936, 'hye_Armn': 1012, 'hun_Latn': 1012, 'lao_Laoo': 1012, 'pbt_Arab': 1009, 'som_Latn': 1012, 'spa_Latn': 1012, 'pes_Arab': 1011, 'gle_Latn': 1012, 'kam_Latn': 561, 'zho_Hans': 1009, 'afr_Latn': 1011, 'ckb_Arab': 1006, 'lin_Latn': 1011, 'sna_Latn': 1012, 'cym_Latn': 1012, 'ory_Orya': 1005, 'zsm_Latn': 936, 'ita_Latn': 1012, 'ibo_Latn': 1012, 'jpn_Jpan': 1012, 'kaz_Cyrl': 1011, 'npi_Deva': 1012, 'smo_Latn': 1012, 'zho_Hant': 1009, 'slv_Latn': 1012, 'urd_Arab': 1010, 'isl_Latn': 1012, 'nob_Latn': 1009, 'gaz_Latn': 1012, 'mri_Latn': 1011, 'arb_Arab': 1012, 'asm_Beng': 1012, 'hrv_Latn': 1006, 'lug_Latn': 1008, 'khm_Khmr': 1012, 'pan_Guru': 1012, 'nya_Latn': 1006, 'yor_Latn': 1012, 'ast_Latn': 917, 'fin_Latn': 1012, 'snd_Arab': 1011, 'jav_Latn': 1012, 'tgk_Cyrl': 1012, 'ell_Grek': 1012, 'ceb_Latn': 1008, 'fra_Latn': 1011, 'guj_Gujr': 1012, 'khk_Cyrl': 1012, 'cat_Latn': 1009, 'ind_Latn': 997, 'eng_Latn': 1004, 'amh_Ethi': 1012, 'uzn_Latn': 1009, 'bul_Cyrl': 1012, 'bos_Latn': 1012}\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(results_dir_gemini):\n",
    "    if file.endswith(\".csv\"):  # Process only .txt files\n",
    "        language_code = file.replace(\".csv\", \"\")\n",
    "        correct_answer = flores_l[language_code]\n",
    "        \n",
    "        file_path = os.path.join(results_dir_gemini, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        matches = (df['gemini_answer'] == correct_answer).sum()\n",
    "        scores_gemini[language_code] = matches\n",
    "print(scores_gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a303b528-63d5-41b6-8e54-6bcf41d13b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mar_Deva': 1010, 'umb_Latn': 51, 'wol_Latn': 976, 'mlt_Latn': 1012, 'kan_Knda': 1012, 'bel_Cyrl': 1012, 'tgl_Latn': 1012, 'luo_Latn': 741, 'nld_Latn': 1011, 'ces_Latn': 1012, 'hau_Latn': 1012, 'glg_Latn': 946, 'swe_Latn': 1012, 'ben_Beng': 1012, 'vie_Latn': 1012, 'mkd_Cyrl': 1009, 'rus_Cyrl': 1009, 'kat_Geor': 1012, 'slk_Latn': 999, 'mya_Mymr': 1012, 'deu_Latn': 1012, 'tam_Taml': 1011, 'kor_Hang': 1012, 'azj_Latn': 1006, 'tur_Latn': 1011, 'por_Latn': 1012, 'kea_Latn': 340, 'mal_Mlym': 1012, 'hin_Deva': 1000, 'tha_Thai': 1011, 'lit_Latn': 1012, 'srp_Cyrl': 1009, 'oci_Latn': 949, 'lvs_Latn': 1012, 'est_Latn': 1011, 'swh_Latn': 1012, 'heb_Hebr': 1012, 'dan_Latn': 1004, 'tel_Telu': 1012, 'ltz_Latn': 1010, 'ukr_Cyrl': 1011, 'pol_Latn': 1012, 'nso_Latn': 1008, 'zul_Latn': 991, 'ron_Latn': 1012, 'xho_Latn': 778, 'hye_Armn': 1012, 'hun_Latn': 1012, 'lao_Laoo': 1012, 'pbt_Arab': 957, 'som_Latn': 1012, 'spa_Latn': 1011, 'pes_Arab': 1009, 'gle_Latn': 1011, 'kam_Latn': 88, 'zho_Hans': 1006, 'afr_Latn': 1009, 'ckb_Arab': 1012, 'lin_Latn': 1001, 'sna_Latn': 1011, 'cym_Latn': 1012, 'ory_Orya': 1012, 'zsm_Latn': 975, 'ita_Latn': 1012, 'ibo_Latn': 1012, 'jpn_Jpan': 1010, 'kaz_Cyrl': 1010, 'npi_Deva': 1012, 'smo_Latn': 1011, 'zho_Hant': 1005, 'slv_Latn': 1004, 'urd_Arab': 1007, 'isl_Latn': 1012, 'nob_Latn': 1002, 'gaz_Latn': 1012, 'mri_Latn': 1011, 'arb_Arab': 1010, 'asm_Beng': 1010, 'hrv_Latn': 936, 'lug_Latn': 1002, 'khm_Khmr': 1012, 'pan_Guru': 1012, 'nya_Latn': 997, 'yor_Latn': 1011, 'ast_Latn': 630, 'fin_Latn': 1012, 'snd_Arab': 1012, 'jav_Latn': 850, 'tgk_Cyrl': 1011, 'ell_Grek': 1012, 'ceb_Latn': 1003, 'fra_Latn': 1011, 'guj_Gujr': 1011, 'khk_Cyrl': 1012, 'cat_Latn': 1010, 'ind_Latn': 922, 'eng_Latn': 993, 'amh_Ethi': 1010, 'uzn_Latn': 1012, 'bul_Cyrl': 1010, 'bos_Latn': 1010}\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(results_dir_gemma):\n",
    "    if file.endswith(\".csv\"):  # Process only .txt files\n",
    "        language_code = file.replace(\".csv\", \"\")\n",
    "        correct_answer = flores_l[language_code]\n",
    "        \n",
    "        file_path = os.path.join(results_dir_gemma, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        matches = (df['gemma3_answer'] == correct_answer).sum()\n",
    "        scores_gemma[language_code] = matches\n",
    "print(scores_gemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae9adf97-b33a-4afc-a2ec-6f5930deeb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tgl_Latn', 'kea_Latn', 'zho_Hant', 'mri_Latn', 'nya_Latn']\n"
     ]
    }
   ],
   "source": [
    "keys = [k for k, v in scores_gpt.items() if v < 100]\n",
    "\n",
    "print(keys)  # Output: ['a', 'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc5bff1c-a258-49b5-94ac-d7bd154c8a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_languages = list(flores_l.keys())\n",
    "language_mapping = pd.read_csv('language_mapping.csv')\n",
    "language_mapping_index = language_mapping.set_index('FLORES-200 code')['Language'].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec29db2e-55d2-4470-b85e-18e7405f0475",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_name_array = []\n",
    "for lang in all_languages:\n",
    "    language_name_array.append(language_mapping_index[lang])\n",
    "\n",
    "        \n",
    "old_results_df = pd.read_csv('old_results.csv')\n",
    "lang_family = old_results_df.set_index('language_code')['language_family'].to_dict()\n",
    "\n",
    "lang_family_array = []\n",
    "for lang in all_languages:\n",
    "    lang_family_array.append(lang_family[lang])\n",
    "\n",
    "\n",
    "gpt_array = []\n",
    "for lang in all_languages:\n",
    "    gpt_array.append(round(scores_gpt[lang]/10.12,1))\n",
    "\n",
    "gemini_array = []\n",
    "for lang in all_languages:\n",
    "    gemini_array.append(round(scores_gemini[lang]/10.12,1))\n",
    "\n",
    "gemma_array = []\n",
    "for lang in all_languages:\n",
    "    gemma_array.append(round(scores_gemma[lang]/10.12,1))\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    \"language_name\": language_name_array,\n",
    "    \"language_code\": all_languages,\n",
    "    \"language_family\": lang_family_array,\n",
    "    \"Accuracy gpt-4o\": gpt_array,\n",
    "    \"Accuracy gemini2-Flash\": gemini_array,\n",
    "    \"Accuracy Gemma3-27B\": gemma_array\n",
    "\n",
    "})\n",
    "\n",
    "result_df.to_csv('overall_results_lid.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "028f9313-d18b-4ee0-b585-45615fd9b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('overall_results_lid.csv')\n",
    "z=df2.groupby('language_family') \\\n",
    "       .agg({'language_name':'size','Accuracy gpt-4o':'mean','Accuracy gemini2-Flash':'mean','Accuracy Gemma3-27B':'mean'} ) \\\n",
    "       .rename(columns={'language_name':'count'}) \\\n",
    "       .sort_values(by=['count'], ascending=False) \\\n",
    "       .reset_index().round(1)\n",
    "z.to_csv('overall_by_family_lid.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0abe6c-ea67-4eda-9727-45b75cd71dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemma3-env",
   "language": "python",
   "name": "gemma3-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
